{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependencies\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import Conv2D, Activation, MaxPool2D, Dropout, Dense, BatchNormalization, Flatten\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import tarfile\n",
    "import dlib\n",
    "import time\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_landmarks(filename):\n",
    "    frame = cv2.imread(filename, cv2.IMREAD_UNCHANGED)\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    clahe_image = clahe.apply(frame)\n",
    "    detections = detector(clahe_image,1)\n",
    "    \n",
    "    for k,d in enumerate(detections): \n",
    "        shape = predictor(clahe_image, d)\n",
    "        for i in range(1,68):\n",
    "            cv2.circle(frame, (shape.part(i).x, shape.part(i).y), 1, (0,0,255), thickness=2) \n",
    "    cv2.imshow(filename, frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def classify_jaffe(filename):\n",
    "    if(re.search(r'(..\\.AN)', filename)):\n",
    "        print(0)\n",
    "        return 0\n",
    "    if(re.search(r'(..\\.DI)', filename)):\n",
    "        print(1)\n",
    "        return 1\n",
    "    elif(re.search(r'(..\\.FE)', filename)):\n",
    "        print(2)\n",
    "        return 2\n",
    "    elif(re.search(r'(..\\.HA)', filename)):\n",
    "        print(3)\n",
    "        return 3\n",
    "    elif(re.search(r'(..\\.SA)', filename)):\n",
    "        print(4)\n",
    "        return 4\n",
    "    elif(re.search(r'(..\\.SU)', filename)):\n",
    "        print(5)\n",
    "        return 5\n",
    "    elif(re.search(r'(..\\.NE)', filename)):\n",
    "        print(6)\n",
    "        return 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory already exists\n",
      "jaffe\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "o_Dir = \"data_landmarks\"\n",
    "dataset_jaffe = \"jaffe\"\n",
    "if not os.path.exists(o_Dir):\n",
    "    print(\"Making data_landmark directory\")\n",
    "    os.mkdir(o_Dir)\n",
    "else:\n",
    "    print(\"Output directory already exists\")\n",
    "for (dirpath, dirnames, filenames) in os.walk(dataset_jaffe):\n",
    "        print(dirpath)\n",
    "        for filename in filenames:\n",
    "            if(re.search(r'\\.tiff', filename) or re.search(r'\\.jpg', filename) or re.search(r'\\.png', filename) or re.search(r'\\.jpeg', filename)):\n",
    "                filename = dirpath+\"/\"+filename\n",
    "                label = classify_jaffe(filename)\n",
    "                #filenameimg = cv2.imread(dirpath+\"/\"+filename, cv2.IMREAD_UNCHANGED)\n",
    "                #cv2.imshow(filename,filenameimg)\n",
    "                get_landmarks(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set up some required objects\n",
    "video_capture = cv2.VideoCapture(0) #Webcam object\n",
    "#detector = dlib.get_frontal_face_detector() #Face detector\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\") #Landmark identifier. Set the filename to whatever you named the downloaded file\n",
    "###\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-c\", \"--cascade\", required=True, help = \"haarcascade_frontalface_default.xml\")\n",
    "#ap.add_argument(\"-p\", \"--shape-predictor\", required=True, help=\"path to facial landmark predictor\")\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "detector = cv2.CascadeClassifier(args[\"cascade\"])\n",
    "#predictor = dlib.shape_predictor(args[\"shape_predictor\"])\n",
    "\n",
    "#facec = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "fno=0\n",
    "detections=()\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "    #frame=cv2.imread('a.jpg',1)\n",
    "    fno+=1;\n",
    "    if(False):\n",
    "        pass\n",
    "    else:\n",
    "        print(fno)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        clahe_image = clahe.apply(gray)\n",
    "        #faces = facec.detectMultiScale(clache_image, 1.3, 5)\n",
    "        # for (x, y, w, h) in faces:\n",
    "         #   fc = gray_fr[y:y+h, x:x+w]\n",
    "          #  roi = cv2.resize(fc, (48, 48))\n",
    "        detections = detector(clahe_image, 1) #Detect the faces in the image\n",
    "        #print(detections)\n",
    "    for k,d in enumerate(detections): #For each detected face\n",
    "        shape = predictor(clahe_image, d) #Get coordinates\n",
    "        for i in range(1,68): #There are 68 landmark points on each face\n",
    "            cv2.circle(frame, (shape.part(i).x, shape.part(i).y), 1, (0,0,255), thickness=2) #For each point, draw a red circle with thickness2 on the original frame\n",
    "    cv2.imshow(\"image\", frame) #Display the frame\n",
    "    \n",
    "    if cv2.waitKey(1) == 27: #Exit program when the user presses 'q'\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
