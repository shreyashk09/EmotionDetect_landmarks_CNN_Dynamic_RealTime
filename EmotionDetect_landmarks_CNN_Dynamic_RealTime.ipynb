{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#dependencies\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import Conv2D, Activation, MaxPool2D, Dropout, Dense, BatchNormalization, Flatten\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import tarfile\n",
    "import dlib\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import itertools as it\n",
    "from PIL import Image\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimise_pts(x,y):\n",
    "    subset=[]\n",
    "    i=0\n",
    "    nose_tip=np.asarray((np.mean(x[30:36]),np.mean(y[30:36])))\n",
    "    leye=np.asarray((np.mean(x[36:42]),np.mean(y[36:42])))\n",
    "    reye=np.asarray((np.mean(x[42:48]),np.mean(y[42:48])))\n",
    "    scale_dist=np.mean([np.linalg.norm(nose_tip-leye),np.linalg.norm(nose_tip-reye)])\n",
    "    for lip_x,lip_y in zip(it.combinations(x[48:68],2),it.combinations(y[48:68],2)):#190\n",
    "        x0=lip_x[0]-lip_x[1]\n",
    "        y0=lip_y[0]-lip_y[1]\n",
    "        dist=np.linalg.norm([x0,y0])\n",
    "        subset.append(dist)\n",
    "    for leyebr_x,leyebr_y in zip(x[17:22],y[17:22]):#30\n",
    "        for leye_x, leye_y in zip(x[36:42],y[36:42]):\n",
    "            x1= leyebr_x - leye_x\n",
    "            y1= leyebr_y - leye_y\n",
    "            dist=np.linalg.norm([x1,y1])\n",
    "            subset.append(dist)\n",
    "    for reyebr_x,reyebr_y in zip(x[22:27],y[22:27]):#30\n",
    "        for reye_x, reye_y in zip(x[42:48],y[42:48]):\n",
    "            x2= reyebr_x - reye_x\n",
    "            y2= reyebr_y - reye_y\n",
    "            dist=np.linalg.norm([x2,y2])\n",
    "            subset.append(dist)\n",
    "    for jaw_x, jaw_y in zip(x[5:12],y[5:12]):#7\n",
    "        x3 = jaw_x-nose_tip[0]\n",
    "        y3 = jaw_y-nose_tip[1]\n",
    "        dist = np.linalg.norm([x3,y3])\n",
    "        subset.append(dist)\n",
    "    for nl_x,nl_y in zip(x[48:60],y[48:60]):#12==269\n",
    "        x4 = nl_x-nose_tip[0]\n",
    "        y4 = nl_y-nose_tip[1]\n",
    "        dist = np.linalg.norm([x4,y4])\n",
    "        subset.append(dist)\n",
    "    subset=np.array(subset)\n",
    "    subset = subset/scale_dist*100\n",
    "    return subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_landmarks(frame):\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    clahe_image = clahe.apply(frame)\n",
    "    detections = detector(clahe_image,1)\n",
    "    x=[]\n",
    "    y=[]\n",
    "    result_data=[]\n",
    "    for k,d in enumerate(detections): \n",
    "        shape = predictor(clahe_image, d)\n",
    "        for i in range(1,68):\n",
    "            x.append(float(shape.part(i).x))\n",
    "            y.append(float(shape.part(i).y))\n",
    "            cv2.circle(frame, (shape.part(i).x, shape.part(i).y), 1, (0,0,255), thickness=2) \n",
    "        result_data.append(optimise_pts(x,y))\n",
    "    #cv2.imshow(\"filename\", frame)\n",
    "    return result_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_jaffe(filename):\n",
    "    if(re.search(r'(..\\.AN)', filename)):\n",
    "        return 0\n",
    "    if(re.search(r'(..\\.DI)', filename)):\n",
    "        return 1\n",
    "    elif(re.search(r'(..\\.FE)', filename)):\n",
    "        return 2\n",
    "    elif(re.search(r'(..\\.HA)', filename)):\n",
    "        return 3\n",
    "    elif(re.search(r'(..\\.SA)', filename)):\n",
    "        return 4\n",
    "    elif(re.search(r'(..\\.SU)', filename)):\n",
    "        return 5\n",
    "    elif(re.search(r'(..\\.NE)', filename)):\n",
    "        return 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making data_landmark directory\n",
      "start of pixel appending\n",
      "jaffe\n",
      "appended to csv\n"
     ]
    }
   ],
   "source": [
    "o_Dir = \"data_landmarks\"\n",
    "#dataset_jaffe = \"jaffe\"\n",
    "dataset_jaffe = \"train_dir\"\n",
    "data_file = []\n",
    "label=[]\n",
    "if not os.path.exists(o_Dir):\n",
    "    print(\"Making data_landmark directory\")\n",
    "    os.mkdir(o_Dir)\n",
    "else:\n",
    "    print(\"Output directory already exists\")\n",
    "import csv\n",
    "print(\"start of pixel appending\")\n",
    "with open(o_Dir+'/'+ dataset_jaffe+\" trn_pixels.csv\", 'w') as csvfile:\n",
    "    dw = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for (dirpath, dirnames, filenames) in os.walk(\"jaffe\"):\n",
    "            print(dirpath)\n",
    "            for filename in filenames:\n",
    "                if(re.search(r'\\.tiff', filename) or re.search(r'\\.jpg', filename) or re.search(r'\\.png', filename) or re.search(r'\\.jpeg', filename)):\n",
    "                    filename = dirpath+\"/\"+filename\n",
    "                    label.append(classify_jaffe(filename))\n",
    "                    data_file = get_landmarks(cv2.imread(filename,cv2.IMREAD_UNCHANGED))\n",
    "                    for i in data_file:\n",
    "                        dw.writerow(i)\n",
    "print(\"appended to csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels appended to csv\n"
     ]
    }
   ],
   "source": [
    "with open(o_Dir+'/'+ dataset_jaffe+\" trn_label.csv\", 'w') as csvfile:\n",
    "    lblw = csv.writer(csvfile)\n",
    "    lblw.writerow(label)\n",
    "print(\"labels appended to csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all data reshaped\n"
     ]
    }
   ],
   "source": [
    "### fer database creation\n",
    "data_comp = tarfile.open(\"fer2013.tar\") \n",
    "ds = pd.read_csv(data_comp.extractfile(\"fer2013/fer2013.csv\"))\n",
    "train = ds[[\"emotion\", \"pixels\"]][ds[\"Usage\"] == \"Training\"]\n",
    "train['pixels'] = train['pixels'].apply(lambda x: np.fromstring(x, sep=' '))\n",
    "train_pix = np.vstack(train['pixels'].values)\n",
    "# test = ds[[\"emotion\", \"pixels\"]][ds[\"Usage\"] == \"PublicTest\"]\n",
    "# test['pixels'] = test['pixels'].apply(lambda x: np.fromstring(x, sep=' '))\n",
    "# test_pix = np.vstack(test['pixels'].values)\n",
    "train_pix = train_pix.reshape(-1,48,48)\n",
    "print(\"all data reshaped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ind = np.array(train[\"emotion\"])\n",
    "# test_ind = np.array(test[\"emotion\"])\n",
    "train_ind.shape#, test_ind.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory already exists\n",
      "start of pixel appending\n",
      "appended to csv\n",
      "labels appended to csv\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_pix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-046ba2c2eb3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mlblw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"labels appended to csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mtest_pix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_pix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_pix' is not defined"
     ]
    }
   ],
   "source": [
    "o_Dir = \"data_landmarks\"\n",
    "#dataset_fer = \"fer2013\"\n",
    "dataset_fer = \"train_dir\"\n",
    "temp_image = \"saveddd.jpg\"\n",
    "data_file = []\n",
    "label= train_ind\n",
    "if not os.path.exists(o_Dir):\n",
    "    print(\"Making data_landmark directory\")\n",
    "    os.mkdir(o_Dir)\n",
    "else:\n",
    "    print(\"Output directory already exists\")\n",
    "import csv\n",
    "print(\"start of pixel appending\")\n",
    "with open(o_Dir+'/'+ dataset_fer+\" trn_pixels.csv\", 'a') as csvfile:\n",
    "    dw = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    sh=train_pix.shape[0]\n",
    "    train_pix = list(train_pix)\n",
    "    for filen in range(sh):\n",
    "        filename = Image.fromarray(train_pix[filen]).convert('RGB')\n",
    "        filename.save(temp_image)\n",
    "        img = cv2.imread(temp_image,0)\n",
    "        o_data = get_landmarks(img)\n",
    "        for i in o_data:\n",
    "            dw.writerow(i)\n",
    "print(\"appended to csv\")\n",
    "with open(o_Dir+'/'+ dataset_fer+\" trn_label.csv\", 'a') as csvfile:\n",
    "    lblw = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    lblw.writerow(label)\n",
    "print(\"labels appended to csv\")\n",
    "#test_pix = test_pix.reshape(-1,48,48,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading\n",
      "start of pixel reading\n"
     ]
    }
   ],
   "source": [
    "# reading csv file as whole\n",
    "o_Dir = \"data_landmarks\"\n",
    "dataset_fer = \"train_dir\"\n",
    "train_data=[]\n",
    "train_label=[]\n",
    "if not os.path.exists(o_Dir):\n",
    "    print(\"no traing file found\")\n",
    "else:\n",
    "    print(\"reading\")\n",
    "    import csv\n",
    "    print(\"start of pixel reading\")\n",
    "    with open(o_Dir+'/'+ dataset_fer+\" trn_pixels.csv\", 'r') as csvfile:\n",
    "        rd = csv.reader(csvfile)\n",
    "        for row in rd:\n",
    "            row = list(map(float, row))\n",
    "            train_data.append(row)\n",
    "    with open(o_Dir+'/'+ dataset_fer+\" trn_label.csv\", 'r') as csvfile:\n",
    "        rd = csv.reader(csvfile)\n",
    "        for row in rd:\n",
    "            row = list(map(int, row))\n",
    "            train_label.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17719, 250)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = np.vstack(train_data)\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 4429750 into shape (48,48,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-95d5ceebc18a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#train_data = np.vstack(train_data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# test_ind = np.array(test[\"emotion\"])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 4429750 into shape (48,48,1)"
     ]
    }
   ],
   "source": [
    "#train_data = np.vstack(train_data)\n",
    "train_data = train_data.reshape(-1,10,25,1)\n",
    "train_label = np.array(train_label)  \n",
    "# test_ind = np.array(test[\"emotion\"])\n",
    "train_label = np_utils.to_categorical(train_data)\n",
    "# test_data = test_pix.reshape(-1,48,48,1)\n",
    "# test_ind = np_utils.to_categorical(test_ind)\n",
    "train_ind.shape\n",
    "#     , test_ind.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, 5, data_format=\"channels_last\", kernel_initializer=\"he_normal\", \n",
    "                 input_shape=(48, 48, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv2D(64, 5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(32, 3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv2D(32, 3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(7))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(14,3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.suptitle('Optimizer : Adam', fontsize=10)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.plot(res.history['loss'], color='b', label='Training Loss')\n",
    "plt.plot(res.history['val_loss'], color='r', label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.plot(res.history['acc'], color='b', label='Training Accuracy')\n",
    "plt.plot(res.history['val_acc'], color='r', label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(test_pix, test_ind, verbose=0)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "import numpy as np\n",
    "\n",
    "class FacialExpressionModel(object):\n",
    "    EMOTIONS_LIST = [\"Angry\", \"Disgust/fear/surprise\",\"Sad\",\"Happy\", \"Neutral\"]\n",
    "\n",
    "    def __init__(self, model_json_file, model_weights_file):\n",
    "        # load model from JSON file\n",
    "        with open(model_json_file, \"r\") as json_file:\n",
    "            loaded_model_json = json_file.read()\n",
    "            self.loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "        # load weights into the new model\n",
    "        self.loaded_model.load_weights(model_weights_file)\n",
    "        print(\"Model loaded from disk\")\n",
    "        self.loaded_model.summary()\n",
    "\n",
    "    def predict_emotion(self, img):\n",
    "        self.preds = self.loaded_model.predict(img)\n",
    "\n",
    "        return FacialExpressionModel.EMOTIONS_LIST[np.argmax(self.preds)]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "rgb = cv2.VideoCapture(0)\n",
    "facec = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "def __get_data__():\n",
    "    _, fr = rgb.read()\n",
    "    gray = cv2.cvtColor(fr, cv2.COLOR_BGR2GRAY)\n",
    "    faces = facec.detectMultiScale(gray, 1.3, 5)\n",
    "    return faces, fr, gray\n",
    "\n",
    "def start_app(cnn):\n",
    "    skip_frame = 10\n",
    "    data = []\n",
    "    flag = False\n",
    "    ix = 0\n",
    "    while True:\n",
    "        ix += 1\n",
    "        \n",
    "        faces, fr, gray_fr = __get_data__()\n",
    "        for (x, y, w, h) in faces:\n",
    "            fc = gray_fr[y:y+h, x:x+w]\n",
    "            \n",
    "            roi = cv2.resize(fc, (48, 48))\n",
    "            pred = cnn.predict_emotion(roi[np.newaxis, :, :, np.newaxis])\n",
    "\n",
    "            cv2.putText(fr, pred, (x, y), font, 1, (255, 255, 0), 2)\n",
    "            cv2.rectangle(fr,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "        cv2.imshow('Filter', fr)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = FacialExpressionModel(\"model1.json\", \"chkPt1.h5\")\n",
    "    start_app(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
