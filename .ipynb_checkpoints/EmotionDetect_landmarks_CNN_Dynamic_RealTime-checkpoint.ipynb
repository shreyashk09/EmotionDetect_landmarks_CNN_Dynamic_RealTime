{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependencies\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import Conv2D, Activation, MaxPool2D, Dropout, Dense, BatchNormalization, Flatten\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import tarfile\n",
    "import dlib\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import itertools as it\n",
    "from PIL import Image\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimise_pts(x,y):\n",
    "    subset=[]\n",
    "    i=0\n",
    "    nose_tip=np.asarray((np.mean(x[30:36]),np.mean(y[30:36])))\n",
    "    leye=np.asarray((np.mean(x[36:42]),np.mean(y[36:42])))\n",
    "    reye=np.asarray((np.mean(x[42:48]),np.mean(y[42:48])))\n",
    "    scale_dist=np.mean([np.linalg.norm(nose_tip-leye),np.linalg.norm(nose_tip-reye)])\n",
    "    for lip_x,lip_y in zip(it.combinations(x[48:68],2),it.combinations(y[48:68],2)):#171\n",
    "        x0=lip_x[0]-lip_x[1]\n",
    "        y0=lip_y[0]-lip_y[1]\n",
    "        dist=np.linalg.norm([x0,y0])\n",
    "        subset.append(dist)\n",
    "    for leyebr_x,leyebr_y in zip(x[17:22],y[17:22]):#30\n",
    "        for leye_x, leye_y in zip(x[36:42],y[36:42]):\n",
    "            x1= leyebr_x - leye_x\n",
    "            y1= leyebr_y - leye_y\n",
    "            dist=np.linalg.norm([x1,y1])\n",
    "            subset.append(dist)\n",
    "    for reyebr_x,reyebr_y in zip(x[22:27],y[22:27]):#30\n",
    "        for reye_x, reye_y in zip(x[42:48],y[42:48]):\n",
    "            x2= reyebr_x - reye_x\n",
    "            y2= reyebr_y - reye_y\n",
    "            dist=np.linalg.norm([x2,y2])\n",
    "            subset.append(dist)\n",
    "    for jaw_x, jaw_y in zip(x[5:12],y[5:12]):#7\n",
    "        x3 = jaw_x-nose_tip[0]\n",
    "        y3 = jaw_y-nose_tip[1]\n",
    "        dist = np.linalg.norm([x3,y3])\n",
    "        subset.append(dist)\n",
    "    for nl_x,nl_y in zip(x[48:60],y[48:60]):#12\n",
    "        x4 = nl_x-nose_tip[0]\n",
    "        y4 = nl_y-nose_tip[1]\n",
    "        dist = np.linalg.norm([x4,y4])\n",
    "        subset.append(dist)\n",
    "    for leyebr_x,leyebr_y, reyebr_x,reyebr_y in zip(x[17:22],y[17:22],x[22:27],y[22:27]):==255\n",
    "        x5 = leyebr_x - nose_tip[0]\n",
    "        y5 = leyebr_y - nose_tip[1]\n",
    "        dist1=np.linalg.norm([x5,y5])\n",
    "        x6 = reyebr_x - nose_tip[0]\n",
    "        y6 = reyebr_y - nose_tip[1]\n",
    "        dist2=np.linalg.norm([x6,y6])\n",
    "        dist= (dist1+dist2)/2\n",
    "        subset.append(dist)\n",
    "    subset.append(0)\n",
    "    subset=np.array(subset)\n",
    "    subset = subset/scale_dist*100\n",
    "    return subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_landmarks(frame):\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    clahe_image = clahe.apply(frame)\n",
    "    detections = detector(clahe_image,1)\n",
    "    x=[]\n",
    "    y=[]\n",
    "    result_data=[]\n",
    "    noi=-1\n",
    "    for k,d in enumerate(detections): \n",
    "        noi=k\n",
    "        shape = predictor(clahe_image, d)\n",
    "        for i in range(1,68):\n",
    "            x.append(float(shape.part(i).x))\n",
    "            y.append(float(shape.part(i).y))\n",
    "            cv2.circle(frame, (shape.part(i).x, shape.part(i).y), 1, (0,0,255), thickness=2) \n",
    "        result_data.append(optimise_pts(x,y))\n",
    "    #cv2.imshow(\"filename\", frame)\n",
    "    return result_data, noi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_jaffe(filename):\n",
    "    if(re.search(r'(..\\.AN)', filename)):\n",
    "        return 0\n",
    "    if(re.search(r'(..\\.DI)', filename)):\n",
    "        return 1\n",
    "    elif(re.search(r'(..\\.FE)', filename)):\n",
    "        return 2\n",
    "    elif(re.search(r'(..\\.HA)', filename)):\n",
    "        return 3\n",
    "    elif(re.search(r'(..\\.SA)', filename)):\n",
    "        return 4\n",
    "    elif(re.search(r'(..\\.SU)', filename)):\n",
    "        return 5\n",
    "    elif(re.search(r'(..\\.NE)', filename)):\n",
    "        return 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory already exists\n",
      "start of pixel appending\n",
      "jaffe\n",
      "appended to csv\n"
     ]
    }
   ],
   "source": [
    "o_Dir = \"data_landmarks\"\n",
    "#dataset_jaffe = \"jaffe\"\n",
    "dataset_jaffe = \"train_dir\"\n",
    "data_file = []\n",
    "if not os.path.exists(o_Dir):\n",
    "    print(\"Making data_landmark directory\")\n",
    "    os.mkdir(o_Dir)\n",
    "else:\n",
    "    print(\"Output directory already exists\")\n",
    "import csv\n",
    "print(\"start of pixel appending\")\n",
    "with open(o_Dir+'/'+ dataset_jaffe+\" trn_label.csv\", 'w') as csvfile1:\n",
    "    lblw = csv.writer(csvfile1)\n",
    "    with open(o_Dir+'/'+ dataset_jaffe+\" trn_pixels.csv\", 'w') as csvfile2:\n",
    "        dw = csv.writer(csvfile2, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        for (dirpath, dirnames, filenames) in os.walk(\"jaffe\"):\n",
    "                print(dirpath)\n",
    "                for filename in filenames:\n",
    "                    if(re.search(r'\\.tiff', filename) or re.search(r'\\.jpg', filename) or re.search(r'\\.png', filename) or re.search(r'\\.jpeg', filename)):\n",
    "                        filename = dirpath+\"/\"+filename\n",
    "                        data_file, noi = get_landmarks(cv2.imread(filename,cv2.IMREAD_UNCHANGED))\n",
    "                        if(noi == -1):\n",
    "                            continue\n",
    "                        elif:\n",
    "                            label=(classify_jaffe(filename))\n",
    "                            for i in data_file:\n",
    "                                dw.writerow(i)\n",
    "                                lblw.writerow(label)\n",
    "print(\"appended to csv\")\n",
    "print(\"labels appended to csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all data reshaped\n"
     ]
    }
   ],
   "source": [
    "### fer database creation\n",
    "data_comp = tarfile.open(\"fer2013.tar\") \n",
    "ds = pd.read_csv(data_comp.extractfile(\"fer2013/fer2013.csv\"))\n",
    "train = ds[[\"emotion\", \"pixels\"]][ds[\"Usage\"] == \"Training\"]\n",
    "train['pixels'] = train['pixels'].apply(lambda x: np.fromstring(x, sep=' '))\n",
    "train_pix = np.vstack(train['pixels'].values)\n",
    "# test = ds[[\"emotion\", \"pixels\"]][ds[\"Usage\"] == \"PublicTest\"]\n",
    "# test['pixels'] = test['pixels'].apply(lambda x: np.fromstring(x, sep=' '))\n",
    "# test_pix = np.vstack(test['pixels'].values)\n",
    "train_pix = train_pix.reshape(-1,48,48)\n",
    "print(\"all data reshaped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ind = np.array(train[\"emotion\"])\n",
    "# test_ind = np.array(test[\"emotion\"])\n",
    "train_ind.shape#, test_ind.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory already exists\n",
      "start of pixel appending\n",
      "appended to csv\n",
      "labels appended to csv\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_pix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-046ba2c2eb3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mlblw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"labels appended to csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mtest_pix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_pix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_pix' is not defined"
     ]
    }
   ],
   "source": [
    "o_Dir = \"data_landmarks\"\n",
    "#dataset_fer = \"fer2013\"\n",
    "dataset_fer = \"train_dir\"\n",
    "temp_image = \"saveddd.jpg\"\n",
    "data_file = []\n",
    "label= train_ind\n",
    "if not os.path.exists(o_Dir):\n",
    "    print(\"Making data_landmark directory\")\n",
    "    os.mkdir(o_Dir)\n",
    "else:\n",
    "    print(\"Output directory already exists\")\n",
    "import csv\n",
    "print(\"start of pixel appending\")\n",
    "with open(o_Dir+'/'+ dataset_fer+\" trn_pixels.csv\", 'a') as csvfile1:\n",
    "    lblw = csv.writer(csvfile1, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    with open(o_Dir+'/'+ dataset_fer+\" trn_label.csv\", 'a') as csvfile2:\n",
    "        dw = csv.writer(csvfile2, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        sh=train_pix.shape[0]\n",
    "        train_pix = list(train_pix)\n",
    "        for filen, lb in zip(range(sh),label):\n",
    "            filename = Image.fromarray(train_pix[filen]).convert('RGB')\n",
    "            filename.save(temp_image)\n",
    "            img = cv2.imread(temp_image,0)\n",
    "            o_data, noi = get_landmarks(img)\n",
    "            if(noi == -1):\n",
    "                continue\n",
    "            else:\n",
    "                for i in o_data:\n",
    "                    dw.writerow(i)\n",
    "                    lblw.writerow(lb)\n",
    "print(\"appended to csv\")\n",
    "print(\"labels appended to csv\")\n",
    "#test_pix = test_pix.reshape(-1,48,48,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading\n",
      "start of pixel reading\n"
     ]
    }
   ],
   "source": [
    "# reading csv file as whole\n",
    "o_Dir = \"data_landmarks\"\n",
    "dataset_fer = \"train_dir\"\n",
    "train_data=[]\n",
    "train_label=[]\n",
    "if not os.path.exists(o_Dir):\n",
    "    print(\"no traing file found\")\n",
    "else:\n",
    "    print(\"reading\")\n",
    "    import csv\n",
    "    print(\"start of pixel reading\")\n",
    "    with open(o_Dir+'/'+ dataset_fer+\" trn_pixels.csv\", 'r') as csvfile:\n",
    "        rd = csv.reader(csvfile)\n",
    "        for row in rd:\n",
    "            row = list(map(float, row))\n",
    "            train_data.append(row)\n",
    "    with open(o_Dir+'/'+ dataset_fer+\" trn_label.csv\", 'r') as csvfile:\n",
    "        rd = csv.reader(csvfile)\n",
    "        for row in rd:\n",
    "            train_label+=row\n",
    "train_label = list(map(int, train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17719, 250)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = np.vstack(train_data)\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28922,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label = np.array(train_label)\n",
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_data = np.vstack(train_data)\n",
    "train_data = train_data.reshape(-1,10,25,1)\n",
    "train_label = np.array(train_label)  \n",
    "# test_ind = np.array(test[\"emotion\"])\n",
    "train_label = np_utils.to_categorical(train_data)\n",
    "# test_data = test_pix.reshape(-1,48,48,1)\n",
    "# test_ind = np_utils.to_categorical(test_ind)\n",
    "train_ind.shape\n",
    "#     , test_ind.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 9, 21, 64)         704       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 9, 21, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 9, 21, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 17, 64)         41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 8, 17, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 8, 17, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 6, 32)          6176      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 4, 6, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 4, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 32)          3104      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 4, 4, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7)                 903       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 118,855\n",
      "Trainable params: 118,215\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, (2,5), data_format=\"channels_last\", kernel_initializer=\"he_normal\", \n",
    "                 input_shape=(10, 25, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv2D(64, (2,5)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(32, (1,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv2D(32, (1,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(7))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-90fc0d73149f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                  \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                  \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m                  \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckPoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                  verbose=2)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_data' is not defined"
     ]
    }
   ],
   "source": [
    "checkPoint = ModelCheckpoint(filepath='chkPt1.h5', verbose=1, save_best_only=True)\n",
    "res = model.fit(train_pix, train_ind, epochs=16,\n",
    "                 shuffle=True,\n",
    "                 batch_size=100, \n",
    "                 validation_data=(test_data, test_label),\n",
    "                 callbacks=[checkPoint], \n",
    "                 verbose=2)\n",
    "\n",
    "# save model to json\n",
    "model_json = model.to_json()\n",
    "with open(\"model1.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-b1a4477dafee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Optimizer : Adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'upper right'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'res' is not defined"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(14,3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.suptitle('Optimizer : Adam', fontsize=10)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.plot(res.history['loss'], color='b', label='Training Loss')\n",
    "plt.plot(res.history['val_loss'], color='r', label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.plot(res.history['acc'], color='b', label='Training Accuracy')\n",
    "plt.plot(res.history['val_acc'], color='r', label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-fbdf7fa6e43d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_data' is not defined"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_data, test_label, verbose=0)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "import numpy as np\n",
    "\n",
    "class FacialExpressionModel(object):\n",
    "    EMOTIONS_LIST = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"]\n",
    "\n",
    "    def __init__(self, model_json_file, model_weights_file):\n",
    "        # load model from JSON file\n",
    "        with open(model_json_file, \"r\") as json_file:\n",
    "            loaded_model_json = json_file.read()\n",
    "            self.loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "        self.loaded_model.load_weights(model_weights_file)\n",
    "        print(\"Model loaded from disk\")\n",
    "        self.loaded_model.summary()\n",
    "\n",
    "    def predict_emotion(self, img):\n",
    "        self.preds = self.loaded_model.predict(img)\n",
    "        return FacialExpressionModel.EMOTIONS_LIST[np.argmax(self.preds)]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "rgb = cv2.VideoCapture(0)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "def start_app(cnn):\n",
    "    while True:\n",
    "\n",
    "        ret, frame = rgb.read()\n",
    "        fr = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        data, noi = get_landmarks(fr)\n",
    "        data= np.array(data)\n",
    "#         print(data)\n",
    "#         for roi in data:\n",
    "#             pred = cnn.predict_emotion(roi.reshape(10,25,1))\n",
    "#             cv2.putText(frame, pred, (0, 0), font, 1, (255, 255, 0), 2)\n",
    "            #cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "        cv2.imshow('Filter', frame)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "#     model = FacialExpressionModel(\"model1.json\", \"chkPt1.h5\")\n",
    "    start_app(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
